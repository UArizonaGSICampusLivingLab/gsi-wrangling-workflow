---
title: "Green Stormwater Infrastructure Data Wrangling"
author: "Eric R. Scott"
date: "`r Sys.Date()`"
output: html_document
resource_files:
- renv.lock
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
zentracloud::setZentracloudOptions(
  token = Sys.getenv("ZENTRACLOUD_TOKEN"),
  domain = "default"
)

library(boxr)
library(jose)
library(tidyverse)
library(zentracloud)
source("R/gsi_get_data.R")
```

<!--
## First time publishing

Publishing this workflow to Posit Connect will fail the first time because the environment variable `BOX_TOKEN_TEXT` is unset.  But, you still can find the app on viz.datascience.arizona.edu and add that env var.  Then, re-publish, and it should work.
-->
## Box authorization

```{r auth}
box_auth_service(token_text = Sys.getenv("BOX_TOKEN_TEXT"))
# box_auth() ## If you want to run locally use this instead of box_auth_service()
dir_id <- "233031886906"
box_setwd(dir_id)
```

## Wrangling workflow

```{r update_data}
#list current files
files <- box_ls() |> as_tibble()

#does example_data.csv exist already?
if ("gsi_living_lab_data.csv" %in% files$name) {
  old_dat <- files |> 
    filter(name == "gsi_living_lab_data.csv") |> 
    pull(id) |> 
    box_read(read_fun = readr::read_csv)
  prev_end <- max(old_dat$datetime) |> with_tz("America/Phoenix")
} else {
  old_dat <- tibble()
  prev_end <- ymd("2023-06-05", tz = "America/Phoenix") #first date of data
}

# Get the data and wrangle it

new_dat <- gsi_get_data(start = prev_end)

# bind old to new and write back to box
all_dat <- 
  bind_rows(old_dat, new_dat) |> 
  filter(!is.na(sensor)) |> # this is somewhat redundant, but having this in gsi_get_data() only removes these from new data
  distinct() |> #remove duplicate rows
  arrange(datetime) 
```

Missing data due to a device being offline is only indicated by missing datetimes.  For easier nicer plotting, it's probably better to fill those missing datetimes in.

```{r}
#Create data frame of expected datetimes for all device, sensor, port combinations in the current data
expected_datetimes <- 
  expand_grid(
    datetime = seq(min(all_dat$datetime), max(all_dat$datetime), by = "hour"),
    device_sensor_port = unique(paste(all_dat$device_sn, all_dat$sensor, all_dat$port, sep = "_"))
  ) |> 
  separate_wider_delim(device_sensor_port, delim = "_", names = c("device_sn", "sensor", "port")) |> 
  mutate(port = as.numeric(port))

#Join to full data to add rows of NAs in all the data columns
all_dat_final <- full_join(all_dat, expected_datetimes)

```


## Write data to box

```{r}
box_write(all_dat_final, "gsi_living_lab_data.csv", write_fun = readr::write_csv)
```

