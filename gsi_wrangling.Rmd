---
title: "Green Stormwater Infrastructure Data Wrangling"
author: "Eric R. Scott"
date: "`r Sys.Date()`"
output: html_document
resource_files:
- renv.lock
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
zentracloud::setZentracloudOptions(
  token = Sys.getenv("ZENTRACLOUD_TOKEN"),
  domain = "default"
)

library(boxr)
library(jose)
library(tidyverse)
library(zentracloud)
library(httr2)
library(jsonlite)
source("R/gsi_get_data.R")
source("R/gsi_get_eto.R")
source("R/calc_hi.R")
source("R/calc_wind_chill.R")
```

<!--
## First time publishing

Publishing this workflow to Posit Connect will fail the first time because the environment variable `BOX_TOKEN_TEXT` is unset.  But, you still can find the app on viz.datascience.arizona.edu and add that env var.  Then, re-publish, and it should work.
-->
## Box authorization

```{r auth}
box_auth_service(token_text = Sys.getenv("BOX_TOKEN_TEXT"))
# box_auth() ## If you want to run locally use this instead of box_auth_service()
dir_id <- "250527085917"
box_setwd(dir_id)
#list current files
files <- box_ls() |> as_tibble()
```

## Wrangling workflow

### Hourly data

```{r update_data}
#does gsi_living_lab_data.csv exist already?
if ("gsi_living_lab_data.csv" %in% files$name) {
  old_dat <- files |> 
    filter(name == "gsi_living_lab_data.csv") |> 
    pull(id) |> 
    box_read(read_fun = readr::read_csv)
  prev_end <- max(old_dat$datetime) |> with_tz("America/Phoenix")
} else {
  old_dat <- tibble()
  prev_end <- ymd("2023-06-05", tz = "America/Phoenix") #first date of data
}

# Get the data and wrangle it
new_dat <-
  gsi_get_data(start = prev_end)
```

#### Add calculated variables

Add columns for adjusted temperature (wind chill and heat index) and plant available water.

```{r calc_vars}
new_dat <- 
  new_dat |>
  mutate(
    air_temperature_adj.value = calc_hi(air_temperature.value, relative_humidity.value) |>
      calc_wind_chill(wind_speed.value) |>
      round(digits = 1),
    paw.value = (water_content.value - 0.06) / 0.11 * 100
)
```

#### Append existing data

```{r append_new_data}
all_dat <- 
  bind_rows(old_dat, new_dat) |> 
  filter(!is.na(sensor)) |> # this is somewhat redundant, but having this in gsi_get_data() only removes these from new data
  distinct() |> #remove duplicate rows
  arrange(datetime) 
```

Missing data due to a device being offline is only indicated by missing datetimes. This next chunk makes missing datetimes explicit.

```{r explicit_na}
all_dat_final <-
  all_dat |> 
  complete(
    nesting(device_sn, sensor, port),
    datetime = seq(min(datetime), max(datetime), by = "hour")
  ) |> 
  distinct() #remove duplicate rows again, just in case.
```

### ETo

Get site_info.csv from box

```{r eto_siteinfo}
site_info <- 
  files |> 
  filter(name == "site_info.csv") |> 
  pull(id) |> 
  box_read()

inputs <-
  site_info |> 
  filter(sensor_model == "ATMOS41") |> 
  select(device_sn, port_num = port, wind_height = depth_height_m, elevation = Elevation, latitude = Latitude)
```

Use site info to get most recent ETo values for all locations from API

```{r eto_get}
eto_list <- pmap(inputs, gsi_get_eto)
eto_new <- list_rbind(eto_list)
```

The last date of `eto_new` is not reliable as of 02-09-2024.  It has different values compared to the same date in `eto_prev.`  My guess is this is due to partial days being summarized instead of rounding off to the nearest day when getting the prev 30 days.  I'll just remove it.

```{r}
eto_new <- eto_new |> filter(datetime != min(datetime, na.rm = TRUE))
```

Read in previously saved ETo data and join.

```{r eto_update}
if ("gsi_living_lab_ETo.csv" %in% files$name) {
  eto_prev <- 
    files |> 
    filter(name == "gsi_living_lab_ETo.csv") |> 
    pull(id) |> 
    box_read(read_fun = readr::read_csv)
} else {
  eto_prev <- tibble()
}

eto_full <-
  bind_rows(eto_prev, eto_new) |> 
  arrange(datetime, device_sn) |> 
  distinct() #keep only one row per site per date

#check that there is just one unique value per site per date
ns <- 
  eto_full |>
  count(device_sn, datetime) |>
  pull(n)
if(!all(ns == 1)) {
  stop("More than one unique value for ETo! Reconcile before publishing data")
}

```


## Write data to box

```{r write_box}
box_write(all_dat_final, "gsi_living_lab_data.csv", write_fun = readr::write_csv)
box_write(eto_full, "gsi_living_lab_ETo.csv", write_fun = readr::write_csv)
```

